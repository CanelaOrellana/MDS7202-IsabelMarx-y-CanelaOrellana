{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUZ1dFPHzAHl"
      },
      "source": [
        "<h1><center>Laboratorio 3: Imagenes üì∑</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD8X1uhGzAHq"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesor: Pablo Badilla y Ignacio Meza\n",
        "- Auxiliar: Sebasti√°n Tinoco\n",
        "- Ayudante: Felipe Arias y Diego Cortez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXflExjqzAHr"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Isabel Marx\n",
        "- Nombre de alumno 2: Canela Orellana\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD-V0bbZzAHr"
      },
      "source": [
        "### **Link de repositorio de GitHub:** https://github.com/CanelaOrellana/MDS7202-IsabelMarx-y-CanelaOrellana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4ps04Zt8jVx"
      },
      "source": [
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Asistencia **obligatoria** a instrucciones del lab (viernes 16.15). Luego, pueden quedarse trabajando en las salas o irse.\n",
        "- **No se revisar√°n entregas de personas ausentes**.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias. \n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBLPj1PzAHs"
      },
      "source": [
        "### Temas a tratar:\n",
        "\n",
        "- Programaci√≥n Orientada a Objetos.\n",
        "- Programaci√≥n Funcional.\n",
        "- `Numpy` para manejo de datos en arreglos/tensores.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0umIr3x8jVx"
      },
      "source": [
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Aplicar los paradigmas y buenas pr√°cticas de programaci√≥n vistas hasta este momento.\n",
        "- Comprender y aprovechar las ventajas que nos ofrece la liberia `numpy` con respecto a trabajar en Python 'puro'.\n",
        "- Visualizar aplicaciones de filtros de im√°genes sin el uso de librer√≠as.\n",
        "- Verificar que el uso indiscriminado de `for` puede afectar en la eficiencia en al procesar datos masivos.\n",
        "\n",
        "\n",
        "El laboratorio deber√° ser desarrollado **sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\")**. La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos.\n",
        "\n",
        "El lab estar√° basado en algunos conceptos b√°sicos de procesamiento de im√°genes, por lo que te iremos guiando, paso a paso por cada uno de los t√≥picos a desarrollar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrG4gYabzAHs"
      },
      "source": [
        "## Descripci√≥n del laboratorio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCXbuI5FzAHs"
      },
      "source": [
        "En Data Science son m√∫ltiples las aplicaciones que exigen el uso exhaustivo de listas de varias dimensiones. Estas entidad reciben formalmente el nombre de **arreglos o tensores**.\n",
        "\n",
        "Pensemos en que queremos almacenar objetos en un casillero com√∫n y corriente: podemos pensar que este puede ser representado por una matriz de dos dimensiones: alto y ancho. ¬øQue suceder√° si este casillero nos queda peque√±o y queremos guardar m√°s informaci√≥n del mismo tipo?: La soluci√≥n es simple es agregar otro casillero. Esto puede ser pensado como el aumento de la dimensi√≥n de nuestro objeto, pasando a ser ahora (alto, ancho, id casillero). Esto no es otra cosa que un **tensor de 3 dimensiones**.\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1tb7popMBUSSj4YzD-Ypytoo6n7PbXzuJ\" width=300 height=300 />\n",
        "</center>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMHGLtrjzAHt"
      },
      "source": [
        "### ¬øBueno y que tiene que ver todo esto con las im√°genes?\n",
        "\n",
        "Una imagen es una representaci√≥n visual de una matriz que contiene de n√∫meros que describen intensidades de color (llamados p√≠xeles). Esto visto desde la perspectiva de una imagen en blanco y negro, vendria siendo una matriz que reune las diferentes intensidades de los pixeles desde 0 a 255.\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/1386/1*bV7S0zACdidh11ikjYpLpQ.png\" width=500 height=500 alt=\"Representaci√≥n de una imagen\" />\n",
        "</center>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNQ3QC-azAHt"
      },
      "source": [
        "Cuando las im√°genes poseen colores, las im√°genes vendr√≠an siendo \"sin querer queriendo\", una bella representaci√≥n de lo que es un tensor: estas pueden ser representadas por un tensor de 3 dimensiones que les dan el *ancho, alto y el canal*, en donde son alojados los colores de la imagen.\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/2146/1*icINeO4H7UKe3NlU1fXqlA.jpeg\" width=300 height=300 alt=\"Representaci√≥n de una imagen\" />\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "Como pueden ver, la imagen puede ser interpretada como un tensor de tres dimensiones(un ancho, un alto y la intensidad de cada color) en el a cada posici√≥n $(i,j)$ de la imagen, le asociaremos 3 intensidades de colores RGB (Rojo, Verde y Azul). Estas intensidades ir√°n desde el $0$ al $255$. La combinaci√≥n de estos 3 canales nos permitir√° representar gran parte de los colores que encontramos en la naturaleza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY8B9cZCGXM0"
      },
      "source": [
        "**Instalar paquetes: Si est√°n usando conda**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdo4LdNvGXM0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "!conda install --yes --prefix {sys.prefix} pillow plotly imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBoQtPFpGXM1"
      },
      "source": [
        "**Instalar paquetes: Si est√°n usando pip**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWPEzmMfGXM2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from IPython.display import clear_output \n",
        "!{sys.executable} -m pip install pillow plotly imageio\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVvdr3KWI44v"
      },
      "source": [
        "**En caso de trabajar con colab:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK0F0SbjI5JJ"
      },
      "outputs": [],
      "source": [
        "### DRIVE ISA\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "    !unzip /content/drive/MyDrive/imagenes_lab3.zip\n",
        "except: \n",
        "    print('Ignorando conexi√≥n drive-colab')\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q12jiQo6zAHu"
      },
      "outputs": [],
      "source": [
        "# En este lab usaremos adicionalmente pillow, una estupenda librer√≠a \n",
        "# para manejar im√°genes.\n",
        "# https://pillow.readthedocs.io/en/stable/\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "\n",
        "foto = np.array(Image.open(\"./images_lab/cobija.PNG\").convert(\"RGB\"))\n",
        "\n",
        "# Solo para ejemplificar, usaremos plotly (NO USARLO EN LO QUE QUEDA DEL LAB). \n",
        "# Pero en el restro del laboratorio, matplotlib debe ser usado\n",
        "\n",
        "fig = px.imshow(foto)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63I9Na8OzAHv"
      },
      "source": [
        "Luego, llamando la variable donde alojamos el array podemos ver los valores que componen a esta imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWc68bMGGXM3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(f'N√∫mero de dimensiones: {foto.ndim}')\n",
        "print(f'N√∫mero de elementos por dimensi√≥n: {foto.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9F1g0gAzAHw"
      },
      "source": [
        "Finalmente visualizamos de forma aleatoria los pixeles de cada canal para mostrar sus intensidades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jyj5I87HzAHw"
      },
      "outputs": [],
      "source": [
        "print(f\"Ejemplo de pixel (10, 200) en el canal 0 - Red: {foto[10, 200, 0]}\")\n",
        "print(f\"Ejemplo de pixel (10, 200) en el canal 1 - Green: {foto[10, 200, 1]}\")\n",
        "print(f\"Ejemplo de pixel (10, 200) en el canal 2 - Blue: {foto[10, 200, 2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--KvQcDQzAHw"
      },
      "source": [
        "Con lo anterior, suponiendo que la imagen del \"gatito\" tiene una altura igual a 600 y un ancho de 400, el tensor $G$ que representa a la imagen vendr√° dado por $G[600, 400, 3]$. \n",
        "\n",
        "### Videos\n",
        "\n",
        "Luego, si queremos complejizar a√∫n mas esto y queremos tener tensores que agrupen un conjunto de im√°genes (de igual tama√±o) tendremos lo siguiente:\n",
        "\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRk4BWrH_xi_blsx9Y32OTT8k80vI90udG-Yg&usqp=CAU\" width=300 height=300 alt=\"Representaci√≥n de una imagen\" />\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "Este conjunto de im√°genes nos generar√° la necesidad de producir una nueva dimensi√≥n, esto producto que las dimensiones son los espacios donde alojamos la informaci√≥n, por esto al conjunto de im√°genes le agregaremos una dimensi√≥n que identifica cada una de las im√°genes del conjunto, quedando representada por el tensor $G[0:n_d, 600, 400, 3]$. Por lo general, cuando tenemos im√°genes con dimensionalidad 4 es porque se tratan de videos, o sea una secuencia de im√°genes; el caso se complejiza a√∫n m√°s cuando agregamos sonido y esto se va a las pailas.\n",
        "\n",
        "<blockquote>Dato:\n",
        "La representaci√≥n que posee cada una de las dimensiones puede cambiar dependiendo de la librer√≠a utilizada, en pytorch por ejemplo las dimensiones de una imagen vienen dadas por [batch, canales, alto, ancho] y no [batch, alto, ancho, canales] como en numpy.\n",
        "</blockquote>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJWXUSARGXM4"
      },
      "source": [
        "### ¬øYa, pero esto tiene aplicaciones m√°s all√° de guardar informaci√≥n en casilleros?\n",
        "\n",
        "Para el caso de im√°genes podemos encontrar m√∫ltiples aplicaciones con la manipulaci√≥n de los tensores y operando matem√°ticamente con ellos. Algunas de las aplicaciones m√°s conocidas (y que aplicaremos) son las siguientes:\n",
        "\n",
        "- **Obtener el negativo de una imagen**: Consiste en obtener el color complementario de una imagen, para esto debemos restar la imagen con la m√°xima intensidad que podemos encontrar en una imagen (o sea 255).\n",
        "    \n",
        "    \n",
        "- **Pasar a escala de grises una imagen**: Los valores RGB se convierten a escala de grises mediante la f√≥rmula NTSC: \n",
        "\n",
        "    $$ imagen\\_gris = 0.299 * Rojo + 0.587 * Verde + 0.114 * Azul $$\n",
        "    \n",
        "    Esta f√≥rmula representa la percepci√≥n relativa de la persona promedio del brillo de la luz roja, verde y azul.\n",
        "    \n",
        "    \n",
        "- **Mejora de contraste**: Son m√∫ltiples las t√©cnicas que nos permiten mejorar el contraste de una imagen, pero, una t√©cnica simple para modificar los contrastes consta en obtener un factor de correcci√≥n llamado F en base al contraste deseado (C). Luego, es aplicado en la diferencia entre la imagen y 128. De esta forma obtenemos R, que es la imagen con la mejora de contraste deseada.\n",
        "\n",
        "    $$ F=259*(C+255)/(255*(259-C)) $$\n",
        "    $$ R=F*(img-128)+128 $$\n",
        "  \n",
        "  \n",
        "- **Convoluci√≥n**: Consiste en recorrer una imagen por cada uno de sus canales utilizando una matriz que lleva por nombre Kernel. El kernel, examinar√° los conjuntos de pixeles que recorre, aplicando una multiplicaci√≥n de los valores circundantes ,y sumando todos los valores generados de este producto para generar un nuevo pixel en el tensor de salida.\n",
        "\n",
        "![conv](https://media3.giphy.com/media/i4NjAwytgIRDW/giphy.gif \"miracomorecorre\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R4LylbDzAHx"
      },
      "source": [
        "---\n",
        "\n",
        "# Desarrollo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGaG_HSuzAHx"
      },
      "source": [
        "En base a lo explicado y visto en clases, a continuaci√≥n, deben construir cada uno de los programas solicitados en las actividades se√±aladas m√°s abajo. Est√°s, deben ser desarrollados de forma grupal (**2 personas por grupo**) y, la soluci√≥n no debe ser compartida con personas externas al grupo; si se detecta que dos grupos entregan el mismo trabajo, ser√° considerado plagio y se tomaran medidas al respecto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhNBRbFWzAHy"
      },
      "source": [
        "## 2. Creaci√≥n de Clases y Funciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhISwri4zAHy"
      },
      "source": [
        "#### Importamos librerias utiles üò∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyc33dKdzAHy"
      },
      "outputs": [],
      "source": [
        "# Libreria Core del lab.\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Librerias para graficar\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Nota: Utilizar solo matplot para este lab. NO USAR PLOTLY, \n",
        "# ya que tiene problemas de compatibilidad con imagenes\n",
        "\n",
        "# Funcionalidades dependientes del Sistema Operativo.\n",
        "import os\n",
        "\n",
        "# Librerias utiles para cargar y generar Gifs\n",
        "import imageio\n",
        "from PIL import Image\n",
        "from scipy.signal import convolve2d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUVO-0qBzAHy"
      },
      "source": [
        "### 2.1. Carga de imagenes y visualizaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAvlZriZzAHy"
      },
      "source": [
        "Descomprima el archivo \"images_lab.zip\" en alg√∫n directorio de su computador o plataforma, observen las im√°genes y clasif√≠quenlas a su gusto, para luego en un diccionario cargar y agrupar las diferentes im√°genes (no cree mas de tres llaves).\n",
        "\n",
        "Hecho esto, visualize dos im√°genes y verifique la dimensionalidad de estas im√°genes con el comando *.shape*. Comente la dimensionalidad de las im√°genes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aOic4qDzAHz"
      },
      "source": [
        "### Carga de imagenes en diccionarios\n",
        "\n",
        "Las siguientes celdas de c√≥digo le permitir√° cargar las im√°genes que utilizaremos durante este laboratorio.\n",
        "\n",
        "La primera celda implementa la funci√≥n `from_jpg`, la cual, dado una ruta, carga una im√°gen:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz3zwrcszAHz"
      },
      "outputs": [],
      "source": [
        "def from_jpg(path):\n",
        "    ruta = Path(path)\n",
        "    image = np.array(Image.open(ruta), dtype='int')\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvhiIt-o8jV7"
      },
      "source": [
        "La segunda celda carga las im√°genes y las guarda en un diccionario. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi-5pbO16yny"
      },
      "outputs": [],
      "source": [
        "images = {\n",
        "    \"gatitos\": [\n",
        "        from_jpg(\"./images_lab/gato1.jpg\"),\n",
        "        from_jpg(\"./images_lab/gato2.jpg\"),\n",
        "        from_jpg(\"./images_lab/gato4.jpg\"),\n",
        "    ],\n",
        "    \"Personas\": [\n",
        "        from_jpg(\"./images_lab/personas.jpg\"),\n",
        "        from_jpg(\"./images_lab/gurus.jpg\"),\n",
        "    ],\n",
        "    \"Monos_chinos\": [from_jpg(\"./images_lab/monitos.jpg\")],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaMh8aqgzAHz"
      },
      "source": [
        "### Plot de imagenes\n",
        "A continuaci√≥n, utilice la funci√≥n `def show(imagen)` (definida m√°s abajo) para explorar las im√°genes cargadas en la celda anterior.\n",
        "\n",
        "**Respuesta Esperada**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ngZZ4AxzAH0"
      },
      "outputs": [],
      "source": [
        "def show(imagen):\n",
        "    plt.imshow(imagen)\n",
        "    plt.show()\n",
        "    x, y, z = imagen.shape\n",
        "    print(f'Dimensiones de la imagen: {x}x{y} (Alto x Ancho)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEfbIRk9zAH0",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "show(images['gatitos'][0])\n",
        "# usar show para mostrar las otras im√°genes..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h2wmiQrV3LG"
      },
      "outputs": [],
      "source": [
        "for key in images:\n",
        "  for img in images[key]:\n",
        "    show(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCKqwGRgzAH1"
      },
      "source": [
        "### 2.2 Clase imagenes [2 puntos]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8rLMQmtzAH1"
      },
      "source": [
        "Ahora que sabemos c√≥mo plotear y cargar una imagen, cree una clase llamada \"Imagen\" la que cumpla las siguientes caracter√≠sticas:\n",
        "\n",
        "- [X] Un constructor que tome como argumento una imagen y que lo guarde como un atributo. `__init__` debe comprobar que la imagen es un arreglo de numpy (con `isinstance`) y adicionalmente que este tiene 3 dimensiones. En caso contrario, debe levantar excepciones con mensajes correspondientes al error detectado (ustedes definen el mensaje). \n",
        "- [X] Implemente el m√©todo `show()` que muestre la imagen usando la funci√≥n `plt.show()`.\n",
        "- [X] Implemente el m√©todo `info()` que retorna un string con las dimensiones de la imagen.\n",
        "- [] Sobrecargue el m√©todo m√°gico `__mul__`, `__add__` y `__sub__`(LLEGU√â HASTA __sub__ CANEEE) para realizar operaciones matem√°ticas entre el objeto y arrays, int o floats. Realice la funci√≥n pensando que la operaci√≥n se puede aplicar tanto para izquierda y derecha. Como estamos trabajando con im√°genes los outputs deben ser enteros, por esto se le aconseja utilizar `.astype(int)` para transformar los arrays de salida a un formato legible por matplotlib.\n",
        "- [X] Es importante que para las operaciones `__add__` y `__sub__` implementen una saturaci√≥n de las im√°genes. Es decir, la suma o resta deben dar como valor m√°ximo 255 y/o como valor m√≠nimos mayores o iguales a 0.\n",
        "- [ ] Para el caso de `__mul__` deben implementar un m√©todo que nos permita saturar las im√°genes (es decir que los valores del array no sobrepasen 255) y tambi√©n no nos permita obtener valores inferiores a cero.\n",
        "\n",
        "Implementadas los m√©todos, compruebe que la funcionalidad es la correcta mediante la ejecuci√≥n de los asserts incluidos un par de celdas m√°s abajo.\n",
        "\n",
        "> **Notas:** \n",
        "- Pueden reutilizar el c√≥digo implementado en las celdas anteriores para implementar los m√©todos `show` e `info` . Sin embargo, No invoquen directamente esas funciones.\n",
        "- La idea es que la imagen contenida en la clase sea inmutable, por ende, todos los metodos que modifiquen la imagen contenida en el objeto deberan retornar un nuevo objeto de la clase `Imagen` que contenga la imagen modificada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_avSoFp8jV9"
      },
      "outputs": [],
      "source": [
        "class Imagen:\n",
        "    \"\"\"Clase contenedora de im√°genes\"\"\"\n",
        "    \n",
        "    def __init__(self, img):\n",
        "        if isinstance(img, np.ndarray):\n",
        "            if img.ndim != 3:\n",
        "                raise (\"El argumento debe ser un arreglo de numpy de solo 3 dimensiones\")\n",
        "            if img.shape[-1] != 3:\n",
        "                raise (\n",
        "                    \"El argumento debe ser un arreglo de numpy de solo 3 dimensiones \"\n",
        "                    \"tal que la √∫ltima dimensi√≥n solo tiene 3 canales\"\n",
        "                )\n",
        "            self.imagen = img\n",
        "        else:\n",
        "            raise TypeError(\n",
        "                \"Debes entregar un arreglo de numpy como argumento del constructor de \"\n",
        "                \"Imagen\"\n",
        "            )\n",
        "\n",
        "    def show(self):\n",
        "        \"\"\"Muestra la im√°gen contenida en el objeto.\n",
        "        Su funcionalidad debe ser igual a la de la funci√≥n mostrar_imagen.\n",
        "        \"\"\"\n",
        "        plt.imshow(self.imagen)\n",
        "        plt.show()\n",
        "\n",
        "    def info(self):\n",
        "        \"\"\" Imprime las caracter√≠sticas de la imagen cargada: Alto y ancho.\n",
        "        \"\"\"\n",
        "        x, y, z = self.imagen.shape\n",
        "        print(f'Dimensiones de la imagen: {x}x{y} (Alto x Ancho)')\n",
        "\n",
        "    def __add__(self, other):\n",
        "        \"\"\"Redefine la operaci√≥n + entre imagen y escalar.\n",
        "\n",
        "        # Idea, usar indexado condicial (similar a los filtros de pandas).\n",
        "        # Sumar y luego que en cada pixel mayor a 255 sea asignado el m√°ximo.\n",
        "        # Ver los tests para mas informaci√≥n.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        other : Union[int, np.ndarray]\n",
        "            Escalar o arreglo que ser√° sumado a cada pixel de la imagen\n",
        "        \"\"\"\n",
        "        if type(other) is not np.ndarray:\n",
        "          other = np.array([other], dtype=int)\n",
        "\n",
        "        sum = Imagen(self.imagen)\n",
        "        sum.imagen = sum.imagen.astype(int) + other\n",
        "        lim_0 = sum.imagen >= 0\n",
        "        lim_255 = sum.imagen <= 255\n",
        "\n",
        "        if lim_0 is not np.ones(sum.imagen.shape, dtype=bool):\n",
        "          sum.imagen = (sum.imagen * lim_0)\n",
        "        \n",
        "        if lim_255 is not np.ones(sum.imagen.shape, dtype=bool):\n",
        "          sum.imagen = (((sum.imagen - 255) * lim_255) + 255)\n",
        "\n",
        "        return(sum)\n",
        "\n",
        "    def __radd__(self, other):\n",
        "        \"\"\"Operaci√≥n conmutativa de __add__.\n",
        "\n",
        "        Hint: deber√≠a llamar a __add__...\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        other : Union[int, np.ndarray]\n",
        "            Escalar o arreglo que ser√° sumado a cada pixel de la imagen\n",
        "        \"\"\"\n",
        "        if type(other) is not np.ndarray:\n",
        "          other = np.array([other], dtype=int)\n",
        "\n",
        "        sum = Imagen(self.imagen)\n",
        "        sum.imagen = other + sum.imagen.astype(int)\n",
        "        lim_0 = sum.imagen >= 0\n",
        "        lim_255 = sum.imagen <= 255\n",
        "\n",
        "        if lim_0 is not np.ones(sum.imagen.shape, dtype=bool):\n",
        "          sum.imagen = (sum.imagen * lim_0)\n",
        "        \n",
        "        if lim_255 is not np.ones(sum.imagen.shape, dtype=bool):\n",
        "          sum.imagen = (((sum.imagen - 255) * lim_255) + 255)\n",
        "\n",
        "        return(sum)\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        \"\"\"Redefine la operaci√≥n + entre imagen y escalar.\n",
        "\n",
        "        # Idea, usar indexado condicial (similar a los filtros de pandas).\n",
        "        # Restar y luego que en cada pixel mayor a 255 sea asignado el m√°ximo.\n",
        "        # Caso similar para valores menores a 0, donde debera asignar el minimo a esos pixeles\n",
        "        # Ver los tests para mas informaci√≥n.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        other : Union[int, np.ndarray]\n",
        "            Escalar o arreglo que ser√° sumado a cada pixel de la imagen\n",
        "        \"\"\"\n",
        "        if type(other) is not np.ndarray:\n",
        "          other = np.array([other], dtype=int)\n",
        "\n",
        "        sub = Imagen(self.imagen)\n",
        "        sub.imagen = sub.imagen.astype(int) - other\n",
        "        lim_0 = sub.imagen >= 0\n",
        "        lim_255 = sub.imagen <= 255\n",
        "\n",
        "        if lim_0 is not np.ones(sub.imagen.shape, dtype=bool):\n",
        "          sub.imagen = (sub.imagen * lim_0)\n",
        "        \n",
        "        if lim_255 is not np.ones(sub.imagen.shape, dtype=bool):\n",
        "          sub.imagen = (((sub.imagen - 255) * lim_255) + 255)\n",
        "\n",
        "        return(sub)\n",
        "\n",
        "    def __rsub__(self, other):\n",
        "        \"\"\"Operaci√≥n conmutativa de __sub__.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        other : Union[int, np.ndarray]\n",
        "            Escalar o arreglo que ser√° sumado a cada pixel de la imagen\n",
        "        \"\"\"\n",
        "        if type(other) is not np.ndarray:\n",
        "          other = np.array([other], dtype=int)\n",
        "\n",
        "        sub = Imagen(self.imagen)\n",
        "        sub.imagen = other - sub.imagen.astype(int)\n",
        "        lim_0 = sub.imagen >= 0\n",
        "        lim_255 = sub.imagen <= 255\n",
        "\n",
        "        if lim_0 is not np.ones(sub.imagen.shape, dtype=bool):\n",
        "          sub.imagen = (sub.imagen * lim_0)\n",
        "        \n",
        "        if lim_255 is not np.ones(sub.imagen.shape, dtype=bool):\n",
        "          sub.imagen = (((sub.imagen - 255) * lim_255) + 255)\n",
        "\n",
        "        return(sub)\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        \"\"\"Redefine la operaci√≥n * entre imagen y escalar.\n",
        "\n",
        "        # Idea, usar indexado condicial (similar a los filtros de pandas).\n",
        "        # Sumar y luego que en cada pixel mayor a 255 sea asignado el m√°ximo y \n",
        "        # cada valor inferior a 0 debe ser 0.\n",
        "        # Ver los tests para mas informaci√≥n.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        other : Union[int, np.ndarray]\n",
        "            Escalar o arreglo que ser√° sumado a cada pixel de la imagen\n",
        "        \"\"\"\n",
        "        if type(other) is not np.ndarray:\n",
        "          other = np.array([other], dtype=int)\n",
        "\n",
        "        mul = Imagen(self.imagen)\n",
        "        mul.imagen = mul.imagen.astype(int) * other\n",
        "        lim_0 = mul.imagen >= 0\n",
        "        lim_255 = mul.imagen <= 255\n",
        "\n",
        "        if lim_0 is not np.ones(mul.imagen.shape, dtype=bool):\n",
        "          mul.imagen = (mul.imagen * lim_0)\n",
        "        \n",
        "        if lim_255 is not np.ones(mul.imagen.shape, dtype=bool):\n",
        "          mul.imagen = (((mul.imagen - 255) * lim_255) + 255)\n",
        "\n",
        "        return(mul)\n",
        "\n",
        "    def __rmul__(self, other):\n",
        "        \"\"\"Operaci√≥n conmutativa de __mul__.\n",
        "\n",
        "        Hint: deber√≠a llamar a __mul__...\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        other : Union[int, np.ndarray]\n",
        "            Escalar o arreglo que ser√° sumado a cada pixel de la imagen\n",
        "        \"\"\"\n",
        "        if type(other) is not np.ndarray:\n",
        "          other = np.array([other], dtype=int)\n",
        "\n",
        "        mul = Imagen(self.imagen)\n",
        "        mul.imagen = other * mul.imagen.astype(int)\n",
        "        lim_0 = mul.imagen >= 0\n",
        "        lim_255 = mul.imagen <= 255\n",
        "\n",
        "        if lim_0 is not np.ones(mul.imagen.shape, dtype=bool):\n",
        "          mul.imagen = (mul.imagen * lim_0)\n",
        "        \n",
        "        if lim_255 is not np.ones(mul.imagen.shape, dtype=bool):\n",
        "          mul.imagen = (((mul.imagen - 255) * lim_255) + 255)\n",
        "\n",
        "        return(mul)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCY4YO_7zAH2"
      },
      "source": [
        "**Resultados esperados:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzXTlvARGXM8"
      },
      "outputs": [],
      "source": [
        "gatito = Imagen(images[\"gatitos\"][1])\n",
        "gurus = Imagen(images[\"Personas\"][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHTR1tIRzAH2",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Test show e info.\n",
        "gatito.show()\n",
        "gatito.info()\n",
        "\n",
        "gurus.show()\n",
        "gurus.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL33tmX2J2HT"
      },
      "outputs": [],
      "source": [
        "# Tests de los overload de operadores.\n",
        "\n",
        "# Test __add__\n",
        "# Idea del test: Todos los elementos de la imagen deben ser a lo m√°s 255.\n",
        "\n",
        "# Test __add__\n",
        "assert np.max((gatito + 1000).imagen) == 255\n",
        "\n",
        "# Test __radd__\n",
        "assert np.max((1000 + gatito).imagen) == 255\n",
        "\n",
        "# Test __sub__\n",
        "assert np.min((gatito - (-1000)).imagen) == 255\n",
        "\n",
        "# Test __sub__\n",
        "assert np.max((gatito - 1000).imagen) == 0\n",
        "\n",
        "# Test __rsub__\n",
        "assert np.min((1000 - gatito ).imagen) == 255\n",
        "\n",
        "# Test __mul__ (probar minimo)\n",
        "assert np.max((-555555 * gatito).imagen) == 0\n",
        "\n",
        "# Test __mul__ (probar maximo)\n",
        "assert np.max((555555*gatito).imagen) == 255\n",
        "\n",
        "# Test __rmul__ (probar minimo)\n",
        "assert np.max((gatito*-555555).imagen) == 0\n",
        "\n",
        "# Test __rmul__ (probar maximo)\n",
        "assert np.max((gatito*555555).imagen) == 255\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aH0xix7zAH2"
      },
      "source": [
        "### 2.3 Clase de Procesamiento de Imagenes [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzIun960zAH2"
      },
      "source": [
        "Ahora que comprenden las diferentes dimensiones que componen a una imagen (en la pr√°ctica), ahora realizaremos diferentes tareas de procesamiento de im√°genes. Para esto, deben crear una clase llamada \"`LibImagen`\" que cumpla los siguientes requisitos:\n",
        "\n",
        "- [X] Pasar una imagen a escala de grises, para esto utilice la ecuaci√≥n (1) expuesta en este mismo notebook.\n",
        "- [X] Obtener los canales R, G y B de forma individual.\n",
        "- [X] Crear una funci√≥n que pase a negativo de la imagen alojada.\n",
        "- [X] Mejorar el contraste de una imagen.\n",
        "- [X] Realizar una convoluci√≥n sobre la imagen.\n",
        "- [X] Documentar la clase creada y verificar la documentaci√≥n con el comando help().\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRy7BgrizAH3"
      },
      "source": [
        "> **Nota üóíÔ∏è**: Todo m√©todo debe tomar una Imagen y retornar una nueva Imagen.\n",
        "\n",
        "> **Nota 2**: El tipo de datos del arreglo de la imagen que generen o modifiquen debe ser \"int\". De lo contrario, puede no visualizarse correctamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZvSOH3UzAH3"
      },
      "outputs": [],
      "source": [
        "class LibImagen():\n",
        "\n",
        "    def to_negative(self, img_in):\n",
        "        \"\"\"Convierte imagen a negativo.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_in : Imagen\n",
        "            Objeto Imagen que contiene imagen a procesar.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        img_out\n",
        "            Objeto Imagen con la imagen procesada.\n",
        "        \"\"\"\n",
        "        img = img_in.imagen\n",
        "        img_out = Imagen(255 - img)#.imagen\n",
        "        return img_out\n",
        "    \n",
        "    def to_gray(self, img_in):\n",
        "        \"\"\"\n",
        "        Transforma una imagen en RGB a la escala de grises. \n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_in : Imagen\n",
        "            Objeto Imagen que contiene una imagen.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        img_out\n",
        "            Una que contiene una imagen con 3 canales. \n",
        "            Los 3 canales deben tener los mismos valores.\n",
        "        \"\"\"\n",
        "        img = img_in.imagen\n",
        "        img_out = np.zeros_like(img)\n",
        "        R = img[:,:,0]\n",
        "        V = img[:,:,1]\n",
        "        A = img[:,:,2]\n",
        "\n",
        "        img_gris = 0.299*R + 0.587*V + 0.114*A\n",
        "        img_out[:,:,0] = img_gris\n",
        "        img_out[:,:,1] = img_gris\n",
        "        img_out[:,:,2] = img_gris\n",
        "        img_out = Imagen(img_out.astype(int))\n",
        "        return img_out\n",
        "    \n",
        "    def get_channel(self, img_in, channel):\n",
        "        \"\"\"Obtiene un canal de un color seteando el resto de los canales en 0.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_in : Imagen\n",
        "            Objeto Imagen que contiene una imagen.\n",
        "        channel : str\n",
        "            Nombre del canal que ser√° seleccionado. Valores posibles: ('r','g' o 'b').\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        img_out: \n",
        "            Objeto Imagen que contiene una imagen con 3 canales. \n",
        "            Solo el canal seleccionado debe tener valores distintos a 0.\n",
        "        \"\"\"\n",
        "        img = img_in.imagen\n",
        "        img_out = np.zeros_like(img)\n",
        "        R = img[:,:,0]\n",
        "        V = img[:,:,1]\n",
        "        A = img[:,:,2]\n",
        "\n",
        "        if channel == 'r' or channel == 'R':\n",
        "          R = img[:,:,0]\n",
        "          #ceros = np.zeros_like(R)\n",
        "          img_out[:,:,0] = R\n",
        "        elif channel == 'g' or channel == 'G':\n",
        "          G = img[:,:,1]\n",
        "          img_out[:,:,1] = G\n",
        "        elif channel == 'b' or channel == 'B':\n",
        "          B = img[:,:,2]\n",
        "          img_out[:,:,2] = B\n",
        "        else:\n",
        "          raise ValueError(\n",
        "                'Error ‚ùå: el canal entregado debe ser r, g o b')\n",
        "        \n",
        "        img_out = Imagen(img_out)\n",
        "\n",
        "        return img_out\n",
        "\n",
        "    def set_contrast(self, img_in, C):\n",
        "        \"\"\"Mejora el contraste de una imagen.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_in : Imagen\n",
        "            Objeto Imagen que contiene una imagen.\n",
        "        C : float\n",
        "            Par√°metro que define el ajuste de contraste.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        img_out\n",
        "            Objeto Imagen que contiene una imagen con 3 canales modificados.            \n",
        "        \"\"\"\n",
        "        img = img_in.imagen\n",
        "        F = 259*(C+255)/(255*(259-C))\n",
        "        img_out = Imagen((F*(img-128)+128).astype(int))\n",
        "        return img_out\n",
        "    \n",
        "    def conv_channel(self, img_in, kernel):\n",
        "        \"\"\"Realiza la convoluci√≥n sobre una imagen con el kernel determinado\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_in : Imagen\n",
        "            Objeto Imagen que contiene una imagen\n",
        "        kernel : arreglo de numpy\n",
        "            Arreglo de numpy que representa una matriz, la cual ser√° el kernel de la convoluci√≥n.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Imagen\n",
        "            Objeto Imagen que contiene una imagen que representa la convoluci√≥n de img_in seg√∫n el kernel\n",
        "        \"\"\"\n",
        "        img = img_in.imagen\n",
        "        img_out = []\n",
        "        for i in range(img.shape[-1]):\n",
        "            img_channel = convolve2d(img[:, :, i], \n",
        "                                     kernel, \n",
        "                                     mode=\"same\", \n",
        "                                     boundary=\"symm\")\n",
        "            img_out.append(img_channel)\n",
        "        new_image = np.stack(img_out, axis=2)\n",
        "        new_image[new_image>255], new_image[new_image<0] = 255, 0\n",
        "        return Imagen(new_image.astype(int))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UEAgZsbzAH3"
      },
      "source": [
        "### 2.4 Probar [0,5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP_6WK-hzAH3"
      },
      "source": [
        "**Respuesta Esperada**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZYslVzozAH3"
      },
      "outputs": [],
      "source": [
        "gatito = Imagen(images[\"gatitos\"][1])\n",
        "\n",
        "gatito.show()\n",
        "\n",
        "lib = LibImagen()\n",
        "\n",
        "print('Negativo')\n",
        "lib.to_negative(gatito).show()\n",
        "\n",
        "print('Grayscale')\n",
        "lib.to_gray(gatito).show()\n",
        "\n",
        "print('Selecci√≥n de Canales')\n",
        "lib.get_channel(gatito, \"r\").show()\n",
        "lib.get_channel(gatito, \"g\").show()\n",
        "lib.get_channel(gatito, \"b\").show()\n",
        "\n",
        "print('Mejora de Contraste')\n",
        "lib.set_contrast(gatito, 0).show()\n",
        "\n",
        "print('Convoluci√≥n')\n",
        "kernel = np.array([[-1, -1,  -1], \n",
        "                   [-1,  8,  -1], \n",
        "                   [-1, -1,  -1]])\n",
        "\n",
        "lib.conv_channel(gatito, kernel).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgE7VUPBGXM_"
      },
      "source": [
        "#### Implementar 5 Kernels y probarlos con las imagenes\n",
        "\n",
        "Referencia: \n",
        "https://en.wikipedia.org/wiki/Kernel_(image_processing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r2re1SBGXM_"
      },
      "outputs": [],
      "source": [
        "# Convoluci√≥n\n",
        "kernel_1 = np.array([[0, 0,  0], \n",
        "                   [0,  1,  0], \n",
        "                   [0, 0,  0]]) #Identidad\n",
        "\n",
        "kernel_2 = np.array([[0, -1,  0], \n",
        "                   [-1,  4,  -1], \n",
        "                   [0, -1,  0]]) #Edge detection\n",
        "\n",
        "kernel_3 = (1/16)*np.array([[1, 2,  1], \n",
        "                          [2,  4,  2], \n",
        "                          [1, 2,  1]]) #Gaussian blur\n",
        "\n",
        "kernel_4 = np.array([[3, 2,  3], \n",
        "                    [2,  1,  2], \n",
        "                    [3, 2,  3]])\n",
        "\n",
        "kernel_5 = np.array([[-1, 0,  -1], \n",
        "                    [0,  8,  0], \n",
        "                    [-1, 0,  -1]])\n",
        "\n",
        "lib.conv_channel(gatito, kernel_1).show()\n",
        "lib.conv_channel(gatito, kernel_2).show()\n",
        "lib.conv_channel(gatito, kernel_3).show()\n",
        "lib.conv_channel(gatito, kernel_4).show()\n",
        "lib.conv_channel(gatito, kernel_5).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EsY0IL28jWA"
      },
      "source": [
        "**Comente:**\n",
        "\n",
        "Para finalizar, comente que hace (o deber√≠a hacer) cada filtro convolucional al aplicarlas a su imagen de ejemplo.\n",
        "\n",
        "Se aplicaron Kernels conocidos y kernels inventados, para cada uno de ellos se obtuvo:\n",
        "\n",
        "1. Se aplic√≥ el kernel identidad, por lo que se espera obtener la misma im√°gen que fue entregada y se puede ver que as√≠ fue.\n",
        "\n",
        "2. En este caso, se aplic√≥ un kernel para detecci√≥n de bordes, tiene la misma funci√≥n que el utilizado para probar las respuestas esperadas. Al utilizarlo se pueden apreciar s√≥lo los bordes de la imagen, como si fuera un dibujo a lapiz muy sencillo del gatito, de l√≠neas m√°s delgadas que al utilizar la matriz de las respuestas esperadas.\n",
        "\n",
        "3. Se utiliz√≥ el kernel *Gaussian blur* que debiese entregar un efecto de la imagen difuminada o desenfocada, con los bordes suavizados, de lo cual, se logra apreciar un efecto muy leve y casi impercemptible.\n",
        "\n",
        "4. En este caso se utiliz√≥ un kernel inventado, con el cual se obtuvo la imagen excesivamente iluminada, tanto as√≠ que s√≥lo se logran apreciar los ojos del gatito y ni siquiera se nota que es un gatito, como comentario de este filtro, se puede decir que no es muy √∫til, ya que se pierde gran parte de la informaci√≥n.\n",
        "\n",
        "5. Por √∫ltimo, tambi√©n se utiliz√≥ un kernel inventado y se obtuvo una imagen muy iluminada (como la anterior), pero en este caso si se logran distinguir los bordes m√°s oscuros de la imagen, lo cual podr√≠a ser de utilidad en algunas aplicaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMf4H0YxzPAM"
      },
      "source": [
        "\n",
        "\n",
        "## 3. Secuencias y Detecci√≥n de Movimiento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghgvxYAPzAH4"
      },
      "source": [
        "### 3.2. Secuencia de Imagenes [1,5 punto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6-00O49zAH5"
      },
      "source": [
        "A continuaci√≥n, deben programar una funci√≥n que nos permite resaltar los objetos en movimientos de una secuencia de im√°genes. Para esta parte del laboratorio, deber√° utilizar las im√°genes dispuestas en la carpeta `secuencia_plaza` del archivo zip subido a material docente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG_F54l3zAH5"
      },
      "source": [
        "Primero que todo, cargue la secuencia de im√°genes que se encuentran en el directorio. Para esto, se recomienda utilizar el comando `os.listdir(dir)`, ya que este le facilitar√° la carga de un gran n√∫mero de im√°genes (pruebe el comando y vea que sucede)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_1YVO0hzAH4"
      },
      "outputs": [],
      "source": [
        "path = \"./secuencia_plaza/\"\n",
        "img_names = os.listdir(path)\n",
        "\n",
        "imagenes = np.array(list(map(lambda img: np.array(Image.open(path + img)), img_names)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZQddvjUzAH5"
      },
      "source": [
        "\n",
        "\n",
        "![plaza se mueve](https://media0.giphy.com/media/ZAzlopoHETs5lZQ6EZ/giphy.gif \"plaza\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_lg6R2mzAH5"
      },
      "source": [
        "Para realizar este ejercicio utilizaremos un m√©todo super b√°sico para la eliminaci√≥n de fondo. Para esto sigue la siguiente receta:\n",
        " 1. Pase a escala de grises todas las im√°genes secuenciales.\n",
        " 2. Almacene en una variable la resta de las im√°genes consecutivas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OUI6d0yzAH5"
      },
      "source": [
        "   $$ imagen\\_out = imagen(t) - imagen(t+1) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "830SUbE0zAH5"
      },
      "source": [
        " 3. Establezca un umbral para eliminar algunos artefactos. Pruebe con al menos 3 umbrales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izZbk7mWzAH5"
      },
      "source": [
        "$$ imagen\\_out = imagen\\_out> Umbral $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "356uBZnOzAH6"
      },
      "source": [
        "**Nota**: No es necesario que construya una clase para esta parte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdSByPBmPJRO"
      },
      "outputs": [],
      "source": [
        "def dect_mov(sec_img, umbral=30):\n",
        "    lib = LibImagen()\n",
        "    tot_img = sec_img.shape[0]\n",
        "    img_out = np.zeros_like(sec_img)\n",
        "    for i in range(1,tot_img):\n",
        "      a = lib.to_gray(Imagen(sec_img[i-1])).imagen - lib.to_gray(Imagen(sec_img[i])).imagen\n",
        "      a[a<=umbral] = 0\n",
        "      img_out[i] = a\n",
        "\n",
        "    return(img_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eWMbFhKzAH6"
      },
      "source": [
        "### 3.3 Resultado"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "loOVRMwONdlS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPJ2y5hizAH6"
      },
      "source": [
        "Ahora es tiempo de relajarse y ver si nuestro experimento logra resaltar los objetos en movimiento de esta pol√©mica Plaza, para esto solo ejecute el siguiente C√≥digo y espere. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEyadxL5zAH6"
      },
      "outputs": [],
      "source": [
        "imageio.mimsave('plaza.gif', dect_mov(imagenes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oemL7T4Gesf3"
      },
      "outputs": [],
      "source": [
        "imageio.mimsave('plaza70.gif', dect_mov(imagenes,70))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imageio.mimsave('plaza100.gif', dect_mov(imagenes,100))"
      ],
      "metadata": {
        "id": "3ZXPuXHCKJYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Este umbral es tan alto que ya no se ve casi nada\n",
        "imageio.mimsave('plaza230.gif', dect_mov(imagenes,230))"
      ],
      "metadata": {
        "id": "UFPXCKCVW4KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua_acfVhc6OG"
      },
      "source": [
        "![](plaza.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYQUym9IzAH6"
      },
      "source": [
        "**Ejemplo de resultado esperado:**\n",
        "\n",
        "![resultados](https://media3.giphy.com/media/SKV3bgUzHt0MLJTWW2/giphy.gif \"res\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg4ZMq8ezAH6"
      },
      "source": [
        "# Conclusi√≥n\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "![Gracias Totales!](https://media.giphy.com/media/5xtDaroSIXzLa6dvfI4/giphy.gif \"cerati\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT4vDJzAzAH7"
      },
      "source": [
        "### Referencias lab 1.\n",
        "\n",
        "- http://www.cs.cornell.edu/cv/SummerSchool/Introduction.pdf\n",
        "- https://en.wikipedia.org/wiki/Tensor\n",
        "- https://support.ptc.com/help/mathcad/es/index.html#page/PTC_Mathcad_Help/example_grayscale_and_color_in_images.html\n",
        "- http://w3.unpocodetodo.info/canvas/negativo.php\n",
        "- http://www.dfstudios.co.uk/articles/programming/image-programming-algorithms/image-processing-algorithms-part-5-contrast-adjustment/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCL1lACBzAH7"
      },
      "source": [
        "<br>\n",
        "<center>\n",
        "<img src=\"https://i.kym-cdn.com/photos/images/original/001/194/195/b18.png\" width=100 height=50 />\n",
        "</center>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OgM9KXT8jWD"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "3659beea8029465fac6d214201bb6ced",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Tabla de Contenidos",
      "title_sidebar": "Contenidos",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "405.567px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}