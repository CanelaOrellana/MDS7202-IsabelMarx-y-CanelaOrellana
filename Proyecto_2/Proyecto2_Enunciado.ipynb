{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b9ead8046fc74db1bf0eb99287c3c91e","deepnote_cell_type":"markdown"},"source":["![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"ca18b36a3bd54ad09e518c5b63b08ef6","deepnote_cell_type":"markdown"},"source":["# Proyecto: Riesgo en el Banco Giturra\n","\n","**MDS7202: Laboratorio de Programación Científica para Ciencia de Datos**\n","\n","### Cuerpo Docente:\n","\n","- Profesor: Pablo Badilla, Ignacio Meza De La Jara\n","- Auxiliar: Sebastián Tinoco\n","- Ayudante: Diego Cortez M., Felipe Arias T.\n","\n","_Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir._\n","\n","---\n","### Equipo:\n","\n","- Nombre de alumno 1: Isabel Marx\n","- Nombre de alumno 2: Canela Orellana\n","\n","### **Link de repositorio de GitHub:** https://github.com/CanelaOrellana/MDS7202-IsabelMarx-y-CanelaOrellana\n","\n","---\n","\n","## Reglas\n","\n","- Fecha de entrega: 01/06/2021\n","- **Grupos de 2 personas.**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n","- Estrictamente prohibida la copia.\n","- Pueden usar cualquier material del curso que estimen conveniente.\n"]},{"cell_type":"markdown","metadata":{"cell_id":"20bff171d2954732b74d8f532c21895a","deepnote_cell_type":"markdown"},"source":["---\n"]},{"cell_type":"markdown","metadata":{"cell_id":"7292d5dfddb9408d8999b7c0e63fc55c","deepnote_cell_type":"markdown"},"source":["# Presentación del Problema\n"]},{"cell_type":"markdown","metadata":{"cell_id":"4e407b3b55de4930a31e10cf4e25f51c","deepnote_cell_type":"markdown"},"source":["![](https://www.diarioeldia.cl/u/fotografias/fotosnoticias/2019/11/8/67218.jpg)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"57d46ee3f60b457fa3932bf4ac15a828","deepnote_cell_type":"markdown"},"source":["**Giturra**, un banquero astuto y ambicioso, estableció su propio banco con el objetivo de obtener enormes ganancias. Sin embargo, su reputación se vio empañada debido a las tasas de interés usureras que imponía a sus clientes. A medida que su banco crecía, Giturra enfrentaba una creciente cantidad de préstamos impagados, lo que amenazaba su negocio y su prestigio.\n","\n","Para abordar este desafío, Giturra reconoció la necesidad de reducir los riesgos de préstamo y mejorar la calidad de los préstamos otorgados. Decidió aprovechar la ciencia de datos y el análisis de riesgo crediticio. Contrató a un equipo de expertos para desarrollar un modelo predictivo de riesgo crediticio.\n","\n","Cabe señalar que lo modelos solicitados por el banquero deben ser interpretables. Ya que estos le permitira al equipo comprender y explicar cómo se toman las decisiones crediticias. Utilizando visualizaciones claras y explicaciones detalladas, pudieron identificar las características más relevantes, le permitirá analizar la distribución de la importancia de las variables y evaluar si los modelos son coherentes con el negocio.\n","\n","Para esto Giturra les solicita crear un modelo de riesgo disponibilizandoles una amplia gama de variables de sus usuarios: como historiales de crédito, ingresos y otros factores financieros relevantes, para evaluar la probabilidad de incumplimiento de pago de los clientes. Con esta información, Giturra podra tomar decisiones más informadas en cuanto a los préstamos, ofreciendo condiciones más favorables a aquellos con menor riesgo de impago.\n"]},{"cell_type":"markdown","metadata":{"cell_id":"731884b83ce840b1b52d26a180626317","deepnote_cell_type":"markdown"},"source":["## Instalación de Librerías y Carga de Datos.\n"]},{"cell_type":"markdown","metadata":{"cell_id":"0c0b7aa1618543519231311b567d9bc3","deepnote_cell_type":"markdown"},"source":["Para el desarrollo de su proyecto, utilice el conjunto de datos `dataset.pq` para entrenar un modelo de su elección. Además, se adjunta junto con los datos del proyecto un archivo llamado `requirements.txt` que contiene todas las bibliotecas y versiones necesarias para el desarrollo del proyecto. Se le recomienda levantar un ambiente de `conda` para instalar estas librerías y así evitar cualquier problema con las versiones.\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","## Secciones Requeridas en el Informe\n","\n","La siguiente lista detalla las secciones que debe contener su notebook para resolver el proyecto. \n","Es importante que al momento de desarrollar cada una de las secciones, estas sean escritas en un formato tipo **informe**, donde describan detalladamente cada uno de los puntos realizados.\n"]},{"cell_type":"markdown","metadata":{},"source":["### 1. Introducción [0.5 puntos]\n","\n","_Esta sección es literalmente una muy breve introducción con todo lo necesario para entender que hicieron en su proyecto._\n","\n","- Describir brevemente el problema planteado (¿Qué se intenta predecir?)\n","- Describir brevemente los datos de entrada que les provee el problema.\n","- Describir las métricas que utilizarán para evaluar los modelos generados. Eligan **una métrica** adecuada para el desarrollo del proyecto **según la tarea que deben resolver y la institución a la cuál será su contraparte** y luego justifiquen su elección. Considerando que los datos presentan desbalanceo y que el uso de la métrica 'accuracy' sería incorrecto, enfoquen su elección en una de las métricas precision, recall o f1-score y en la clase que será evaluada.\n","- [Escribir al final] Describir brevemente el modelo que usaron para resolver el problema (incluyendo las transformaciones intermedias de datos).\n","- [Escribir al final] Indicar si lograron resolver el problema a través de su modelo. Indiquen además si creen que los resultados de su mejor modelo son aceptables y como les fue con respecto al resto de los equipos."]},{"cell_type":"markdown","metadata":{},"source":["### 2. Carga de datos Análisis Exploratorio de Datos [Sin puntaje]\n","\n","_La idea de esta sección es que cargen y exploren el dataset para así obtener una idea de como son los datos y como se relacionan con el problema._\n","\n","Cargue los datos y realice un análisis exploratorio de datos para investigar patrones, tendencias y relaciones en un conjunto de datos. Se adjuntan diversos scripts para abodar rápidamente este punto. La descripción de las columnas las pueden encontrar en el siguiente [enlace](https://www.kaggle.com/datasets/parisrohan/credit-score-classification).\n","\n","**NO deben escribir nada**, solo ejecutar el código y encontrar los patrones con los cuales se basaran para generar el modelo."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Libreria Core del lab.\n","import numpy as np\n","import pandas as pd\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split\n","\n","# Pre-procesamiento\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","\n","# Metricas de evaluación\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import cohen_kappa_score\n","\n","#Libreria para plotear\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","import plotly.graph_objects as go"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>age</th>\n","      <th>occupation</th>\n","      <th>annual_income</th>\n","      <th>monthly_inhand_salary</th>\n","      <th>num_bank_accounts</th>\n","      <th>num_credit_card</th>\n","      <th>interest_rate</th>\n","      <th>num_of_loan</th>\n","      <th>delay_from_due_date</th>\n","      <th>...</th>\n","      <th>num_credit_inquiries</th>\n","      <th>outstanding_debt</th>\n","      <th>credit_utilization_ratio</th>\n","      <th>credit_history_age</th>\n","      <th>payment_of_min_amount</th>\n","      <th>total_emi_per_month</th>\n","      <th>amount_invested_monthly</th>\n","      <th>payment_behaviour</th>\n","      <th>monthly_balance</th>\n","      <th>credit_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CUS_0xd40</td>\n","      <td>23.0</td>\n","      <td>Scientist</td>\n","      <td>19114.12</td>\n","      <td>1824.843333</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>809.98</td>\n","      <td>23.933795</td>\n","      <td>NaN</td>\n","      <td>No</td>\n","      <td>49.574949</td>\n","      <td>24.785217</td>\n","      <td>High_spent_Medium_value_payments</td>\n","      <td>358.124168</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CUS_0x21b1</td>\n","      <td>28.0</td>\n","      <td>Teacher</td>\n","      <td>34847.84</td>\n","      <td>3037.986667</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>605.03</td>\n","      <td>32.933856</td>\n","      <td>27.0</td>\n","      <td>No</td>\n","      <td>18.816215</td>\n","      <td>218.904344</td>\n","      <td>Low_spent_Small_value_payments</td>\n","      <td>356.078109</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CUS_0x2dbc</td>\n","      <td>34.0</td>\n","      <td>Engineer</td>\n","      <td>143162.64</td>\n","      <td>12187.220000</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>3.0</td>\n","      <td>8</td>\n","      <td>...</td>\n","      <td>3.0</td>\n","      <td>1303.01</td>\n","      <td>38.374753</td>\n","      <td>18.0</td>\n","      <td>No</td>\n","      <td>246.992319</td>\n","      <td>10000.000000</td>\n","      <td>High_spent_Small_value_payments</td>\n","      <td>895.494583</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CUS_0xb891</td>\n","      <td>55.0</td>\n","      <td>Entrepreneur</td>\n","      <td>30689.89</td>\n","      <td>2612.490833</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>-100.0</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>632.46</td>\n","      <td>27.332515</td>\n","      <td>17.0</td>\n","      <td>No</td>\n","      <td>16.415452</td>\n","      <td>125.617251</td>\n","      <td>High_spent_Small_value_payments</td>\n","      <td>379.216381</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CUS_0x1cdb</td>\n","      <td>21.0</td>\n","      <td>Developer</td>\n","      <td>35547.71</td>\n","      <td>2853.309167</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>-100.0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>943.86</td>\n","      <td>25.862922</td>\n","      <td>31.0</td>\n","      <td>Yes</td>\n","      <td>0.000000</td>\n","      <td>181.330901</td>\n","      <td>High_spent_Small_value_payments</td>\n","      <td>364.000016</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 22 columns</p>\n","</div>"],"text/plain":["  customer_id   age    occupation  annual_income  monthly_inhand_salary  \\\n","0   CUS_0xd40  23.0     Scientist       19114.12            1824.843333   \n","1  CUS_0x21b1  28.0       Teacher       34847.84            3037.986667   \n","2  CUS_0x2dbc  34.0      Engineer      143162.64           12187.220000   \n","3  CUS_0xb891  55.0  Entrepreneur       30689.89            2612.490833   \n","4  CUS_0x1cdb  21.0     Developer       35547.71            2853.309167   \n","\n","   num_bank_accounts  num_credit_card  interest_rate  num_of_loan  \\\n","0                  3                4              3          4.0   \n","1                  2                4              6          1.0   \n","2                  1                5              8          3.0   \n","3                  2                5              4       -100.0   \n","4                  7                5              5       -100.0   \n","\n","   delay_from_due_date  ...  num_credit_inquiries  outstanding_debt  \\\n","0                    3  ...                   4.0            809.98   \n","1                    3  ...                   2.0            605.03   \n","2                    8  ...                   3.0           1303.01   \n","3                    4  ...                   4.0            632.46   \n","4                    1  ...                   4.0            943.86   \n","\n","   credit_utilization_ratio  credit_history_age  payment_of_min_amount  \\\n","0                 23.933795                 NaN                     No   \n","1                 32.933856                27.0                     No   \n","2                 38.374753                18.0                     No   \n","3                 27.332515                17.0                     No   \n","4                 25.862922                31.0                    Yes   \n","\n","   total_emi_per_month amount_invested_monthly  \\\n","0            49.574949               24.785217   \n","1            18.816215              218.904344   \n","2           246.992319            10000.000000   \n","3            16.415452              125.617251   \n","4             0.000000              181.330901   \n","\n","                  payment_behaviour  monthly_balance credit_score  \n","0  High_spent_Medium_value_payments       358.124168            0  \n","1    Low_spent_Small_value_payments       356.078109            0  \n","2   High_spent_Small_value_payments       895.494583            0  \n","3   High_spent_Small_value_payments       379.216381            0  \n","4   High_spent_Small_value_payments       364.000016            0  \n","\n","[5 rows x 22 columns]"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_parquet('dataset.pq')\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Preparación de Datos [0.5 puntos]\n","\n","_Esta sección consiste en generar los distintos pasos para preparar sus datos con el fin de luego poder crear su modelo._\n","\n","#### 3.1 Preprocesamiento con `ColumnTransformer`\n","\n","✅ Convierta las columnas mal leidas a sus tipos correspondientes (float, str, etc...)  \n","\n","✅ Genere un `ColumnTransformer` que:  \n","  - Preprocese datos categóricos y ordinales.\n","  - Escale/estandarice datos numéricos.\n","  - Uitlice `.set_output(transform=\"pandas\")` sobre su `ColumnTransformer` para setear el formato de salida a de las transformaciones a pandas.\n","\n","✅ Luego, pruebe las transformaciones utilizando `fit_transform`.\n","\n","✅ Posteriormente, ejecute un Holdout que le permita más adelante evaluar los modelos."]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["# quantiles age\n","q1 = df['age'].quantile(.01)\n","q3 = df['age'].quantile(.982)\n","mask = df['age'].between(q1, q3, inclusive='both')\n","#df edad filtrada\n","df = df[mask]"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[],"source":["# quantiles num_bank_accounts\n","q1 = df['num_bank_accounts'].quantile(.01)\n","q3 = df['num_bank_accounts'].quantile(.982)\n","mask = df['num_bank_accounts'].between(q1, q3, inclusive='both')\n","#df num_bank_accounts filtrada\n","df = df[mask]"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[],"source":["# quantiles num_credit_card\n","q1 = df['num_credit_card'].quantile(.01)\n","q3 = df['num_credit_card'].quantile(.982)\n","mask = df['num_credit_card'].between(q1, q3, inclusive='both')\n","#df num_credit_card filtrada\n","df = df[mask]"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["# quantiles num_of_loan\n","q3 = df['num_of_loan'].quantile(.982)\n","mask = df['num_of_loan'].between(0, q3, inclusive='both')\n","#df num_of_loan filtrada\n","df = df[mask]"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["# quantiles num_of_delayed_payment\n","q3 = df['num_of_delayed_payment'].quantile(.982)\n","mask = df['num_of_delayed_payment'].between(0, q3, inclusive='both')\n","#df num_of_delayed_payment filtrada\n","df = df[mask]"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[],"source":["mask = df['payment_behaviour']!='!@9#%8'\n","df = df[mask]"]},{"cell_type":"markdown","metadata":{},"source":["Se tienen características que\n","- representan números enteros\n","- representan números reales\n","- representan variables categóricas\n","\n","Cabe mencionar que si bien las variables ```age```, ```delay_from_due_date```, ```num_bank_accounts```, ```num_credit_card```, ```interest_rate``` son enteras, toman muchos valores diferentes (+150) por lo que se les realizarán transformaciones numéricas como a los flotantes y no se les tratará como categorías. "]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>payment_behaviour</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9473</th>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>9474</th>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>9475</th>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>9476</th>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>9477</th>\n","      <td>5.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9478 rows × 1 columns</p>\n","</div>"],"text/plain":["      payment_behaviour\n","0                   3.0\n","1                   0.0\n","2                   1.0\n","3                   2.0\n","4                   3.0\n","...                 ...\n","9473                4.0\n","9474                2.0\n","9475                4.0\n","9476                3.0\n","9477                5.0\n","\n","[9478 rows x 1 columns]"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import OrdinalEncoder\n","\n","categories_order = [['Low_spent_Small_value_payments',\n","                    'High_spent_Small_value_payments',\n","                    'Low_spent_Medium_value_payments',\n","                    'High_spent_Medium_value_payments',\n","                    'Low_spent_Large_value_payments', \n","                    'High_spent_Large_value_payments']]\n","\n","enc = OrdinalEncoder(categories=categories_order)\n","\n","variables_ordinal = df[['payment_behaviour']]\n","\n","#Se entrena el codificador\n","ordinales = enc.fit_transform(variables_ordinal.dropna())\n","pd.DataFrame(ordinales, columns = ['payment_behaviour'])\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["v_flotantes = ['age', 'annual_income', 'monthly_inhand_salary', 'num_bank_accounts', 'num_credit_card', 'interest_rate', 'num_of_loan', 'delay_from_due_date', 'num_of_delayed_payment', 'changed_credit_limit', 'num_credit_inquiries', 'outstanding_debt', 'credit_utilization_ratio', 'credit_history_age', 'total_emi_per_month', 'amount_invested_monthly', 'monthly_balance' ]\n","v_enteras = ['credit_score']\n","v_categoricas = ['occupation', 'payment_of_min_amount', 'payment_behaviour']"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["#Se crea el Column Transformer\n","\n","ct = ColumnTransformer(\n","    transformers=[\n","        ('MinMax', MinMaxScaler(),v_flotantes),\n","        ('OneHot', OneHotEncoder(drop='first') , v_categoricas)]\n","    , remainder=\"passthrough\"\n",")\n","\n","#ct.set_output(transform=\"pandas\")"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>MinMax__age</th>\n","      <th>MinMax__annual_income</th>\n","      <th>MinMax__monthly_inhand_salary</th>\n","      <th>MinMax__num_bank_accounts</th>\n","      <th>MinMax__num_credit_card</th>\n","      <th>MinMax__interest_rate</th>\n","      <th>MinMax__num_of_loan</th>\n","      <th>MinMax__delay_from_due_date</th>\n","      <th>MinMax__num_of_delayed_payment</th>\n","      <th>MinMax__changed_credit_limit</th>\n","      <th>...</th>\n","      <th>OneHot__payment_of_min_amount_No</th>\n","      <th>OneHot__payment_of_min_amount_Yes</th>\n","      <th>OneHot__payment_behaviour_High_spent_Large_value_payments</th>\n","      <th>OneHot__payment_behaviour_High_spent_Medium_value_payments</th>\n","      <th>OneHot__payment_behaviour_High_spent_Small_value_payments</th>\n","      <th>OneHot__payment_behaviour_Low_spent_Large_value_payments</th>\n","      <th>OneHot__payment_behaviour_Low_spent_Medium_value_payments</th>\n","      <th>OneHot__payment_behaviour_Low_spent_Small_value_payments</th>\n","      <th>remainder__customer_id</th>\n","      <th>remainder__credit_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.056984</td>\n","      <td>0.000508</td>\n","      <td>0.102087</td>\n","      <td>0.002277</td>\n","      <td>0.002668</td>\n","      <td>0.000346</td>\n","      <td>0.065204</td>\n","      <td>0.111111</td>\n","      <td>0.002095</td>\n","      <td>0.408652</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>CUS_0xd40</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.057529</td>\n","      <td>0.001168</td>\n","      <td>0.183501</td>\n","      <td>0.001707</td>\n","      <td>0.002668</td>\n","      <td>0.000864</td>\n","      <td>0.063323</td>\n","      <td>0.111111</td>\n","      <td>0.001629</td>\n","      <td>0.274045</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>CUS_0x21b1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.058183</td>\n","      <td>0.005714</td>\n","      <td>0.797502</td>\n","      <td>0.001138</td>\n","      <td>0.003336</td>\n","      <td>0.001209</td>\n","      <td>0.064577</td>\n","      <td>0.180556</td>\n","      <td>0.002095</td>\n","      <td>0.312701</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>CUS_0x2dbc</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.060471</td>\n","      <td>0.000994</td>\n","      <td>0.154946</td>\n","      <td>0.001707</td>\n","      <td>0.003336</td>\n","      <td>0.000518</td>\n","      <td>0.0</td>\n","      <td>0.125</td>\n","      <td>0.002793</td>\n","      <td>0.195122</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>CUS_0xb891</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.056766</td>\n","      <td>0.001198</td>\n","      <td>0.171107</td>\n","      <td>0.004553</td>\n","      <td>0.003336</td>\n","      <td>0.000691</td>\n","      <td>0.0</td>\n","      <td>0.083333</td>\n","      <td>0.00419</td>\n","      <td>0.208698</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>CUS_0x1cdb</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 42 columns</p>\n","</div>"],"text/plain":["  MinMax__age MinMax__annual_income MinMax__monthly_inhand_salary  \\\n","0    0.056984              0.000508                      0.102087   \n","1    0.057529              0.001168                      0.183501   \n","2    0.058183              0.005714                      0.797502   \n","3    0.060471              0.000994                      0.154946   \n","4    0.056766              0.001198                      0.171107   \n","\n","  MinMax__num_bank_accounts MinMax__num_credit_card MinMax__interest_rate  \\\n","0                  0.002277                0.002668              0.000346   \n","1                  0.001707                0.002668              0.000864   \n","2                  0.001138                0.003336              0.001209   \n","3                  0.001707                0.003336              0.000518   \n","4                  0.004553                0.003336              0.000691   \n","\n","  MinMax__num_of_loan MinMax__delay_from_due_date  \\\n","0            0.065204                    0.111111   \n","1            0.063323                    0.111111   \n","2            0.064577                    0.180556   \n","3                 0.0                       0.125   \n","4                 0.0                    0.083333   \n","\n","  MinMax__num_of_delayed_payment MinMax__changed_credit_limit  ...  \\\n","0                       0.002095                     0.408652  ...   \n","1                       0.001629                     0.274045  ...   \n","2                       0.002095                     0.312701  ...   \n","3                       0.002793                     0.195122  ...   \n","4                        0.00419                     0.208698  ...   \n","\n","  OneHot__payment_of_min_amount_No OneHot__payment_of_min_amount_Yes  \\\n","0                              1.0                               0.0   \n","1                              1.0                               0.0   \n","2                              1.0                               0.0   \n","3                              1.0                               0.0   \n","4                              0.0                               1.0   \n","\n","  OneHot__payment_behaviour_High_spent_Large_value_payments  \\\n","0                                                0.0          \n","1                                                0.0          \n","2                                                0.0          \n","3                                                0.0          \n","4                                                0.0          \n","\n","  OneHot__payment_behaviour_High_spent_Medium_value_payments  \\\n","0                                                1.0           \n","1                                                0.0           \n","2                                                0.0           \n","3                                                0.0           \n","4                                                0.0           \n","\n","  OneHot__payment_behaviour_High_spent_Small_value_payments  \\\n","0                                                0.0          \n","1                                                0.0          \n","2                                                1.0          \n","3                                                1.0          \n","4                                                1.0          \n","\n","  OneHot__payment_behaviour_Low_spent_Large_value_payments  \\\n","0                                                0.0         \n","1                                                0.0         \n","2                                                0.0         \n","3                                                0.0         \n","4                                                0.0         \n","\n","  OneHot__payment_behaviour_Low_spent_Medium_value_payments  \\\n","0                                                0.0          \n","1                                                0.0          \n","2                                                0.0          \n","3                                                0.0          \n","4                                                0.0          \n","\n","  OneHot__payment_behaviour_Low_spent_Small_value_payments  \\\n","0                                                0.0         \n","1                                                1.0         \n","2                                                0.0         \n","3                                                0.0         \n","4                                                0.0         \n","\n","  remainder__customer_id remainder__credit_score  \n","0              CUS_0xd40                       0  \n","1             CUS_0x21b1                       0  \n","2             CUS_0x2dbc                       0  \n","3             CUS_0xb891                       0  \n","4             CUS_0x1cdb                       0  \n","\n","[5 rows x 42 columns]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df_parte3 = ct.fit_transform(df)\n","columns = ct.get_feature_names_out()\n","df_parte3 = pd.DataFrame(df_parte3, columns=columns)\n","\n","df_parte3.head()"]},{"cell_type":"markdown","metadata":{},"source":["pd: se intentó utilizar `.set_output(transform=\"pandas\")` como se indicaba, pero no se logró que quedara de la forma deseada"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.2 Holdout \n","\n","Ejecute `train_test_split` para generar un conjunto de entrenamiento y de prueba. \n","\n","Si bien tienen la libertad de generar conjuntos de validación para robustecer sus resultados, este no es requisito obligatorio y no se le asignará puntaje por esto (esto debido a que grid-search ocupa internamente cross validation)."]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["y = df['credit_score']\n","X = df.drop(columns=['credit_score'])\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=17)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.3 Datos nulos.\n","\n","Como habrá visto, existe la posibilidad de que algunos datos sean nulos. En esta sección se le solicita justificar, previo a comenzar el modelado, decidir si conservar e imputar los datos nulos o eliminar las filas. \n","\n","Note que la decisión que tomen aquí puede afectar fuertemente el rendimiento de los modelos. \n","Y como siempre, más adelante tienen el espacio para experimentar con ambas opciones.\n"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"data":{"text/plain":["customer_id                    0\n","age                            0\n","occupation                     0\n","annual_income                  0\n","monthly_inhand_salary       1433\n","num_bank_accounts              0\n","num_credit_card                0\n","interest_rate                  0\n","num_of_loan                    0\n","delay_from_due_date            0\n","num_of_delayed_payment         0\n","changed_credit_limit         195\n","num_credit_inquiries         186\n","outstanding_debt               0\n","credit_utilization_ratio       0\n","credit_history_age           839\n","payment_of_min_amount          0\n","total_emi_per_month            0\n","amount_invested_monthly      427\n","payment_behaviour              0\n","monthly_balance              273\n","credit_score                   0\n","dtype: int64"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.4 Feature Engineering [Bonus - 0.5 puntos]\n","\n","En esta sección, se espera que apliquen su conocimiento y creatividad para identificar y construir características que brinden una mejor orientación a su modelo para identificar los casos deseados. Para motivar la construcción de nuevas características, se recomienda explorar las siguientes posibilidades:\n","\n","- Generar ratios que relacionen variables categóricas con numéricas. Estos ratios permiten capturar relaciones proporcionales o comparativas entre diferentes categorías y valores numéricos.\n","- Combinación de rankings entre variables numéricas y categóricas.\n","- Discretización de variables numéricas a categóricas.\n","- Etc...\n","\n","**Importantes**: Al explorar estas posibilidades no se limiten solo a estas propuestas, pueden aplicar otras técnicas de feature engineering pertinentes para mejorar la capacidad de su modelo para comprender y aprovechar los patrones presentes en los datos."]},{"cell_type":"markdown","metadata":{},"source":["### 4. Baseline [1.5 puntos]\n","\n","_En esta sección deben crear los modelos más básicos posibles que resuelvan el problema dado. La idea de estos modelos son usarlos como comparación para que en el siguiente paso lo puedan mejorar._\n","\n","Implemente, entrene y evalúe varias `Pipeline` enfocadas en resolver el problema de clasificación en donde la diferencia entre estas sea el modelo utilizado.\n","\n","\n","Para esto, cada Pipeline debe:\n","\n","- Tener el `ColumnTransformer` implementado en la sección anterior como primer paso.\n","- Implementar un imputador en caso de haber decidido conservar los datos nulos.\n","- Implementar un clasificador en la salida (ver siguiente lista).\n","  \n","Y además, \n","- Ser evaluado de forma general imprimiendo un `classification_report`.\n","- Calcular y guardar la métrica seleccionada en el punto 1.2 en un arreglo de métricas (guardar nombre y valor de la métrica).\n","\n","Lo anterior debe ser implementado utilizando los siguientes modelos:\n","\n","- `Dummy` con estrategia estratificada.\n","- `LogisticRegression`.\n","- `KNeighborsClassifier`.\n","- `DecisionTreeClassifier`\n","- `SVC`\n","- `RandomForestClassifier` \n","- `LightGBMClassifier` (del paquete `lightgbm`)\n","- `XGBClassifier` (del paquete `xgboost`).\n","\n","\n","Luego, transformando el diccionario de las métricas a un pandas `DataFrame`, ordene según los valores de su métrica de mayor a menor y responda.\n","- ¿Hay algún clasificador entrenado mejor que el azar (`Dummy`)?\n","- ¿Cuál es el mejor clasificador entrenado?\n","- ¿Por qué el mejor clasificador es mejor que los otros?\n","- Respecto al tiempo de entrenamiento, con cual cree que sería mejor experimentar (piense en el tiempo que le tomaría pasar el modelo por una grilla de optimización de hiperparámetros).\n","\n","**Nota**: Puede utilizar un for más una lista con las clases de los modelos mencionados para simplificar el proceso anterior."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### 5. Optimización del Modelo [1.5 puntos]\n","\n","_En esta sección deben mejorar del modelo de clasificación al variar los algoritmos/hiperparámetros que están ocupando._\n","\n","- Instanciar dos nuevas `Pipeline`, similares a la anterior, pero ahora enfocada en buscar el mejor modelo. Para esto, la pipelines debe utilizar el primer y segundo mejor modelo encontrado en el paso anterior.\n","- Usar **`GridSearchCV`** o **`HalvingGridSearchCV`** para tunear hipermarámetros. La primera demorará más que la segunda pero les traerá potencialmente mejores resultados.\n","- **Importante**: Recuerden setear la búsqueda para optimizar la métrica seleccionada en los puntos anteriores.\n","\n","Algunas ideas para mejorar el rendimiento de sus modelos:\n","\n","- Agregar técnicas de seleccion de atributos/características. El parámetro de cuántas características se seleccionan debe ser parametrizable y configurado por el optimizador de hiperparámetros.\n","- Variar el imputador de datos en caso de usarlo."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"8c769111397b49e980ce325911903144","deepnote_cell_type":"markdown"},"source":["\n","\n","#### Bonus\n","\n","1. **Optuna** [0.5 extras]: Pueden probar también [`OptunaSearchCV`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.OptunaSearchCV.html) de la librería [`Optuna`](https://optuna.org/), la cuál es bastante popular para buscar modelos de redes neuronales.\n","2. **Visualización con Optuna** [0.2 extras]: Explore la documentación de visualización de Optuna en el siguiente [link](https://optuna.readthedocs.io/en/stable/reference/visualization/index.html) y realice un análisis sobre el proceso de optimización de hiperparámetros realizado.\n","3. **Imabalanced learn** [0.3 extras]: Al ser el problema desbalanceado, pueden probar técnicas para balancear automáticamente el dataset previo a ejecutar el modelo. Para esto, puede probar con los mecanismos implementados en la librería [Imbalanced learn](https://imbalanced-learn.org/). \n","4. **Probar pycaret (AutoML) [0.3 extras]**.\n","\n","Algunas notas interesantes sobre este proceso:\n","\n","- No se les pide rendimientos cercanos al 100% de la métrica para concretar exitosamente el proyecto. Por otra parte, celebren cada progreso que obtengan.\n","- **Hacer grillas computables**: Si la grilla se va a demorar 1/3 la edad del universo en explorarse completamente, entonces achíquenla a algo que sepan que va a terminar.\n","- Aprovechen el procesamiento paralelo (con `njobs`) para acelerar la búsqueda. Sin embargo, si tienen problemas con la memoria RAM, reduzca la cantidad de jobs a algo que su computador/interprete web pueda procesar.\n","- La pipelines permiten cachear (guardar temporalmente) etapas cuyo cálculo es redudante, como por ejemplo el escalamiento y la imputación, acelerando así la computación. **Importante:** Para esto, cuando ejecuten `GridSearchCV`, agreguen a la pipeline en el parámetro `memory = \".\"`.\n","\n","**Al final de este proceso, seleccione el mejor modelo encontrado, prediga el conjunto de prueba y reporte sus resultados.**"]},{"cell_type":"markdown","metadata":{},"source":["### 6. Interpretabilidad [1.0 puntos]\n","\n","_En esta sección, se espera que los estudiantes demuestren su capacidad para explicar cómo sus modelos toman decisiones utilizando los datos. Dentro del análisis de interpretabilidad propuesto para el modelo, deberán ser capaces de:_\n","\n","- Proponer un método para analizar la interpretabilidad del modelo. Es crucial que puedan justificar por qué el método propuesto es el más adecuado y explicar los alcances que podría tener en su aplicación.\n","- Identificar las características más relevantes del modelo. ¿La distribución de importancia es coherente y equitativa entre todas las variables?\n","- Analizar 10 observaciones aleatorias utilizando un método específico para verificar la coherencia de las interacciones entre las características.\n","- Explorar cómo se relacionan las variables utilizando algún descriptivo de interpretabilidad.\n","- ¿Existen variables irrelevantes en el problema modelado?, ¿Cuales son?.\n","\n","Es fundamental que los estudiantes sean capaces de determinar si su modelo toma decisiones coherentes y evaluar el impacto que podría tener la aplicación de un modelo con esas variables en una población. ¿Es posible que el modelo sea perjudicial o que las estimaciones se basen en decisiones sesgadas?\n","\n","En resumen, esta sección busca que los estudiantes apliquen un enfoque crítico para evaluar la interpretabilidad de su modelo, identificar posibles sesgos y analizar las implicaciones de sus decisiones en la población objetivo."]},{"cell_type":"markdown","metadata":{},"source":["### 7. Concluir [1.0 puntos]\n","\n","_Aquí deben escribir una breve conclusión del trabajo que hicieron en donde incluyan (pero no se limiten) a responder las siguientes preguntas:_\n","\n","- ¿Pudieron resolver exitosamente el problema?\n","- ¿Son aceptables los resultados obtenidos?\n","- ¿En que medida el EDA ayudó a comprender los datos en miras de generar un modelo predictivo?\n","\n","Respecto a la clasificación:\n","\n","- ¿Como fue el rendimiento del baseline para la clasificación?\n","- ¿Pudieron optimizar el baseline para la clasificación?\n","- ¿Que tanto mejoro el baseline de la clasificación con respecto a sus optimizaciones?\n","\n","Finalmente:\n","\n","- ¿Estuvieron conformes con sus resultados?\n","- ¿Creen que hayan mejores formas de modelar el problema?\n","- ¿En general, qué aprendieron del proyecto? ¿Qué no aprendieron y les gustaría haber aprendido?\n","\n","**OJO** si usted decide responder parte de estas preguntas, debe redactarlas en un formato de informe y no responderlas directamente."]},{"cell_type":"markdown","metadata":{"cell_id":"86fadbd406214b998dd528ec52eeecde","deepnote_cell_type":"markdown"},"source":["### Otras Instrucciones\n","\n","Recordar el uso de buenas prácticas de MLOPS como replicabilidad (fijar semillas aleatorias) o el uso del registro de experimentos (con MLFlow). Si bien son opcionales, es altamente recomendado su uso.\n","\n","### 8. Bonus: Implementación de Kedro y FastAPI [1.5 puntos]\n","\n","**OPCIONAL**\n","\n","En esta sección se les solicita utilizar las últimas tecnologías vistas en el curso para la productivización del proyecto de ciencia de datos, centrándose en la organización y gestión de los flujos de trabajo a través de componentes y pipelines, más el servicio del modelo a través del desarrollo de una API.\n","\n","Para esto: \n","\n","1. Genere un proyecto de `Kedro` en donde separe por responsabilidades los nodos/componentes de su proyecto de ciencia de datos en módulos separados. [1.0 puntos]\n","2. Genere un servidor basado en `FastAPI` el cuál a través de un método post, reciba un batch de datos y genere predicciones para cada uno de ellos. [0.5 puntos]\n","\n","Las implementaciones son libres. Es decir, usted decide qué componentes implementar, como usar el catálogo de datos y la parametrización del flujo. Sin embargo, evaluaremos buen uso de los framework, modularización y separación de responsabilidades.\n"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"4a4ad4306407402db0c258f95d5a9abe","kernelspec":{"display_name":"competencia","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
